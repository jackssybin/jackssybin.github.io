title: 实战2之爬取表情包
date: '2019-09-03 20:53:19'
updated: '2019-09-03 20:53:19'
tags: [python学习, scrapy]
permalink: /articles/2019/09/16/1568643753095.html
---
**一、爬取表情包思路（http://www.doutula.com）**

1、打开网站，点击最新套图

2、之后我们可以看到没有套图，我们需要提取每个套图的连接

3、获取连接之后，进入页面提取图片就好了

4、我们可以发现该网站还穿插有广告，我们需要过滤点广告

**二、实战**

关于新建项目我们就不再多说了。

1、首先我们提取第一页的url

![null](https://upload-images.jianshu.io/upload_images/9489193-0e1dec797b7791fd.png?imageMogr2/auto-orient/strip|imageView2/2/w/761/format/webp)

通过上图我们可以发现我们想要的url全在class名为col-sm-9的div下，

红色框的部分为广告。不是a标签，所以我们就不用过滤了。我们直接选取col-sm-9下的直接子节点即可

写下如下代码：

![null](https://upload-images.jianshu.io/upload_images/9489193-60e6de5ae093a07d.png?imageMogr2/auto-orient/strip|imageView2/2/w/1011/format/webp)

值得注意的是在settings.py中需要添加头信息和将robots.txt协议修改为False

![null](https://upload-images.jianshu.io/upload_images/9489193-e9685460ffcd2f3b.png?imageMogr2/auto-orient/strip|imageView2/2/w/846/format/webp)

我们打上断点调试一下：

![null](https://upload-images.jianshu.io/upload_images/9489193-e9ad1881d2ab983f.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

我们发现我们想要的信息已经提取出来了。

注意：在Request中的mate参数，是用来传递参数的，传递给下一个方法使用。使用方法和字典相似。

2、完善item

我们只需要三个字段，什么系列，图片url，图片名称。

![null](https://upload-images.jianshu.io/upload_images/9489193-90360b903a9b99a9.png?imageMogr2/auto-orient/strip|imageView2/2/w/783/format/webp)

3、提取item中我们需要的字段

![null](https://upload-images.jianshu.io/upload_images/9489193-43cab2609f20fda3.png?imageMogr2/auto-orient/strip|imageView2/2/w/957/format/webp)

4、下一页

![null](https://upload-images.jianshu.io/upload_images/9489193-59e30f3c497416b8.png?imageMogr2/auto-orient/strip|imageView2/2/w/907/format/webp)

5、保存

因为对scrapy保存图片没有研究，所以就自己写保存图片的方法。

在pipelines.py种添加如下代码：

![null](https://upload-images.jianshu.io/upload_images/9489193-2dc665230842cff2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

并且在settings.py中添加：

![null](https://upload-images.jianshu.io/upload_images/9489193-3ff5a89dae6507a7.png?imageMogr2/auto-orient/strip|imageView2/2/w/655/format/webp)

6、运行

直接报错，所以我们在settings.py添加头信息

运行一段时候后又报错了，看来需要随机更换表头信息。

这里我们使用第三方库很方便，pip3 install fake_useragent

安装成功后我们在middlewares.py中导入：from fake_useragent import UserAgent

添加如下代码：

![null](https://upload-images.jianshu.io/upload_images/9489193-0d068e62527f447a.png?imageMogr2/auto-orient/strip|imageView2/2/w/916/format/webp)

在settings.py文件中添加

![null](https://upload-images.jianshu.io/upload_images/9489193-d9d5c7f035fa9152.png?imageMogr2/auto-orient/strip|imageView2/2/w/723/format/webp)

运行main文件：

![null](https://upload-images.jianshu.io/upload_images/9489193-d0f96585b3ad55ff.png?imageMogr2/auto-orient/strip|imageView2/2/w/1175/format/webp)

即可。

**小结：**

效果图：

![null](https://upload-images.jianshu.io/upload_images/9489193-af412ddd807d0ad1.png?imageMogr2/auto-orient/strip|imageView2/2/w/729/format/webp)

  

**问题：**

在运行过程中遇到了四个问题：

**1、没有获取大到图片连接：**

可能这个网站有两个版本获取的css方式不一样。

**解决方法：**可以使用xpath中的|（或）来解决

**2、没有获取到图片名称**

**解决方法：**同上

**3、图片名称相同**

**解决方法：**可以使用md5加密后添加，你也可以使用你自己的方法

**4、在图片名中含有？/\等非法字符**

**解决方法：**可以通过正则过滤，如果md5加密，那么一下解决两个问题。

虽然有些图片没有获取到，但是还是爬取了很多。有兴趣的可以尝试去修改。

**完。**